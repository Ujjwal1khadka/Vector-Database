{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \\\n",
    "#   langchain_community \\\n",
    "#   langchain_pinecone \\\n",
    "#   langchain_openai \\\n",
    "#   unstructured \\\n",
    "#   langchain-text-splitters \\\n",
    "#   pinecone-text \\\n",
    "#   langchain-cohere \\\n",
    "#.  cohere    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_community.retrievers import (\n",
    "    PineconeHybridSearchRetriever)\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_core.runnables import Runnable\n",
    "from pinecone import ServerlessSpec\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import pinecone\n",
    "import uuid\n",
    "import os\n",
    "import glob\n",
    "import hashlib\n",
    "from tqdm.autonotebook import tqdm\n",
    "from langchain.storage import InMemoryStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import nltk\n",
    "#  nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch API keys from environment variables\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "\n",
    "\n",
    "# Set the environment variables\n",
    "if openai_api_key:\n",
    "    os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "if pinecone_api_key:\n",
    "    os.environ['PINECONE_API_KEY'] = pinecone_api_key \n",
    "\n",
    "#Verify that the keys are loaded\n",
    "#print(f\"OpenAI API Key: {os.environ.get('OPENAI_API_KEY')}\")\n",
    "#print(f\"Pinecone API Key: {os.environ.get('PINECONE_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/user/Downloads/colab/data'\n",
    "\n",
    "def load_docs(directory):\n",
    "    loader = DirectoryLoader(directory)\n",
    "    docs = loader.load()\n",
    "    return docs\n",
    "\n",
    "docs = load_docs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support@vitafyhealth.com | 1-866-4-Vitafy\n",
      "\n",
      "Billings Module\n",
      "\n",
      "October, 2023\n",
      "\n",
      "All the notifications sen\n",
      "{'source': '/Users/user/Downloads/colab/data/Clients - Comms Module .docx'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[0:100])\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x326fefdd0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x3348cff20>, model='text-embedding-ada-002', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"HUGGINGFACEHUB_API_TOKEN\"\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",  #response time is 9s  #infloat/e5-base-V2 has 3.53sec response time.\n",
    ")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import time\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "if not os.getenv(\"PINECONE_API_KEY\"):\n",
    "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
    "\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "import time\n",
    "\n",
    "index_name = \"test-2\"  # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=3072,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "#pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 2000  \n",
    "chunk_overlap = 500  \n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"test-2\"\n",
    "#vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings)\n",
    "vectorstore = PineconeVectorStore.from_documents(split_docs, embeddings, index_name=index_name)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of the IDs of all records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "\n",
    "# index = pc.Index(\"test-2\")\n",
    "# ids = index.list(namespace='')\n",
    "\n",
    "# for ids in index.list(namespace=''):\n",
    "#     print(ids)\n",
    "    \n",
    "# #['doc1#v1#chunk1', 'doc1#v1#chunk2', 'doc1#v1#chunk3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "\n",
    "# from PyPDF2 import PdfReader  # For reading PDF files\n",
    "# import docx \n",
    "# index_name = \"test-2\"\n",
    "# directory = 'data'\n",
    "# # 1. Upload data from 'data' directory\n",
    "# # Function to read text from different file types\n",
    "# def read_document(file_path):\n",
    "#     if file_path.endswith('.txt'):\n",
    "#         with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#             return file.read()\n",
    "#     elif file_path.endswith('.pdf'):\n",
    "#         with open(file_path, 'rb') as file:\n",
    "#             reader = PdfReader(file)\n",
    "#             return \"\\n\".join(page.extract_text() for page in reader.pages if page.extract_text())\n",
    "#     elif file_path.endswith('.docx'):\n",
    "#         doc = docx.Document(file_path)\n",
    "#         return \"\\n\".join(paragraph.text for paragraph in doc.paragraphs)\n",
    "#     else:\n",
    "#         return None  # Unsupported file type\n",
    "        \n",
    "# # 1. Upload data from 'data' directory\n",
    "# for filename in os.listdir(directory):\n",
    "#     file_path = os.path.join(directory, filename)\n",
    "    \n",
    "#     # Read the content of the document based on its type\n",
    "#     document_text = read_document(file_path)\n",
    "    \n",
    "#     if document_text:  # Only proceed if the document was read successfully\n",
    "#         # 2. Generate embedding for the document\n",
    "#         vector = embeddings.embed_documents([document_text])[0]  # Use embed_documents for document embeddings\n",
    "\n",
    "        \n",
    "#         # 3. Generate a unique vector ID (using the filename without extension)\n",
    "#         #vector_id = os.path.splitext(filename)[0]  # Unique ID based on filename\n",
    "        \n",
    "#         vector_id = str(uuid.uuid4())  # Generate a unique UUID\n",
    "\n",
    "        \n",
    "#         # Prepare metadata (optional)\n",
    "#         metadata = {\n",
    "#             \"source\": filename,\n",
    "#             \"page_content\": document_text[:100]  # Store first 100 characters as a preview (optional)\n",
    "#         }\n",
    "        \n",
    "#         # Upsert the vector into Pinecone\n",
    "#         index.upsert(vectors=[(vector_id, vector)], metadata=metadata)\n",
    "\n",
    "#         # 4. Print vector ID and document name\n",
    "#         print(f\"Uploaded Document - Vector ID: {vector_id}, Document Name: {filename}\")\n",
    "\n",
    "# print(\"All documents uploaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"\"\" summarize ai paper\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abhishek, Amit Kumar Bindal and Dharminder Yadav\n",
      "\n",
      "ARTICLES YOU MAY BE INTERESTED IN\n",
      "\n",
      "Automated implementation of test scenarios by UML combinational diagrams via uniformed algorithm AIP Conference Proceedings 2576, 050012 (2022); https://doi.org/10.1063/5.0105807\n",
      "\n",
      "A machine learning based assistive tool for finding potability of drinking water: An approach towards “Water for Life” AIP Conference Proceedings 2576, 050015 (2022); https://doi.org/10.1063/5.0105800\n",
      "\n",
      "Asynchronous carry look ahead adder using energy efficient pipeline template AIP Conference Proceedings 2576, 050016 (2022); https://doi.org/10.1063/5.0107203\n",
      "\n",
      "AIP Conference Proceedings 2576, 050014 (2022); https://doi.org/10.1063/5.0105723\n",
      "\n",
      "© 2022 Author(s).\n",
      "\n",
      "2576, 050014\n",
      "\n",
      "Abhishek, Amit Kumar Bindal and Dharminder Yadav\n",
      "\n",
      "ARTICLES YOU MAY BE INTERESTED IN\n",
      "\n",
      "Automated implementation of test scenarios by UML combinational diagrams via uniformed algorithm AIP Conference Proceedings 2576, 050012 (2022); https://doi.org/10.1063/5.0105807\n",
      "\n",
      "A machine learning based assistive tool for finding potability of drinking water: An approach towards “Water for Life” AIP Conference Proceedings 2576, 050015 (2022); https://doi.org/10.1063/5.0105800\n",
      "\n",
      "Asynchronous carry look ahead adder using energy efficient pipeline template AIP Conference Proceedings 2576, 050016 (2022); https://doi.org/10.1063/5.0107203\n",
      "\n",
      "AIP Conference Proceedings 2576, 050014 (2022); https://doi.org/10.1063/5.0105723\n",
      "\n",
      "© 2022 Author(s).\n",
      "\n",
      "2576, 050014\n",
      "\n",
      "Abhishek, Amit Kumar Bindal and Dharminder Yadav\n",
      "\n",
      "ARTICLES YOU MAY BE INTERESTED IN\n",
      "\n",
      "Automated implementation of test scenarios by UML combinational diagrams via uniformed algorithm AIP Conference Proceedings 2576, 050012 (2022); https://doi.org/10.1063/5.0105807\n",
      "\n",
      "A machine learning based assistive tool for finding potability of drinking water: An approach towards “Water for Life” AIP Conference Proceedings 2576, 050015 (2022); https://doi.org/10.1063/5.0105800\n",
      "\n",
      "Asynchronous carry look ahead adder using energy efficient pipeline template AIP Conference Proceedings 2576, 050016 (2022); https://doi.org/10.1063/5.0107203\n",
      "\n",
      "AIP Conference Proceedings 2576, 050014 (2022); https://doi.org/10.1063/5.0105723\n",
      "\n",
      "© 2022 Author(s).\n",
      "\n",
      "2576, 050014\n",
      "\n",
      "Abhishek, Amit Kumar Bindal and Dharminder Yadav\n",
      "\n",
      "ARTICLES YOU MAY BE INTERESTED IN\n",
      "\n",
      "Automated implementation of test scenarios by UML combinational diagrams via uniformed algorithm AIP Conference Proceedings 2576, 050012 (2022); https://doi.org/10.1063/5.0105807\n",
      "\n",
      "A machine learning based assistive tool for finding potability of drinking water: An approach towards “Water for Life” AIP Conference Proceedings 2576, 050015 (2022); https://doi.org/10.1063/5.0105800\n",
      "\n",
      "Asynchronous carry look ahead adder using energy efficient pipeline template AIP Conference Proceedings 2576, 050016 (2022); https://doi.org/10.1063/5.0107203\n",
      "\n",
      "AIP Conference Proceedings 2576, 050014 (2022); https://doi.org/10.1063/5.0105723\n",
      "\n",
      "© 2022 Author(s).\n",
      "\n",
      "2576, 050014\n"
     ]
    }
   ],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"\"\" summarize ai paper\"\"\")\n",
    "print(format_docs(retrieved_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an expert LLM assistant specialized in answering questions based solely on the information provided in the uploaded documents (PDF, DOCX, or TXT formats). Use only the information from the documents to respond accurately and clearly to each question.\n",
    "\n",
    "Guidelines:\n",
    "1. Provide concise and informative answers.\n",
    "2. If the answer is not found in the uploaded documents, state, \"The answer is not specifically mentioned in the provided documents.\"\n",
    "3. Avoid using outside knowledge or assumptions. Stick strictly to the content in the documents.\n",
    "4. Maintain a professional and helpful tone thinking you are giving service to the customer for their documents \n",
    "5. Answer for normal conversation question like \"Hi\", \"Hey\", \"Hello\", \"How are you\", and many others questions with answer \"Hello, How can I assist you?\".\n",
    "6. If question is on \"summarize\" or \"summerization\", then summarize the documents and (1/4)th the size of documents.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = template.format(question = keyword, context =  format_docs(retrieved_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': ' summarize ai paper',\n",
       " 'result': \"The context provided does not include specific details about the content of the AI paper authored by Abhishek, Amit Kumar Bindal, and Dharminder Yadav. It only lists the paper's citation and related articles. To provide an accurate summary, I would need more information about the paper's objectives, methodology, findings, and conclusions. If you can provide more details or a specific section of the paper, I would be happy to help summarize it.\"}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=1.0,\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    #chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "\n",
    ")\n",
    "qa.invoke(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_rag_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the parallel chain\n",
    "My_rag_chain = RunnableParallel(\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    ") | custom_rag_template | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "## My chain : Retriever(Pinecone) | custom_rag_template(prompt) | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is not specifically mentioned in the provided documents.\n"
     ]
    }
   ],
   "source": [
    "keyword = \"\"\"summarize ai paper\"\"\"\n",
    "My_rag_chain.invoke(keyword)\n",
    "#print(\"Chat with your Documents:\")\n",
    "print(My_rag_chain.invoke(keyword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, How can I assist you?\n"
     ]
    }
   ],
   "source": [
    "keyword = \"\"\"summarize ai paper\"\"\"\n",
    "My_rag_chain.invoke(keyword)\n",
    "#print(\"Chat with your Documents:\")\n",
    "print(My_rag_chain.invoke(keyword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
